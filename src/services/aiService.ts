// src/services/aiService.ts
import { AISettings, AI_PROVIDERS } from "../types";
import { multiProviderSettings } from "../settings";
import { RoamService } from "./roamService";
import { LLMUtil } from "../utils/llmUtil";

export class AIService {
  // Helper function to get provider for a specific model
  static async getProviderForModel(
    model: string
  ): Promise<{ provider: any; apiKey: string } | null> {
    return LLMUtil.getProviderForModel(model);
  }

  // New method that uses the currently selected model from multiProviderSettings
  static async sendMessageWithCurrentModel(
    userMessage: string,
    context: string
  ): Promise<string> {
    const model = multiProviderSettings.currentModel;
    if (!model) {
      throw new Error(
        "No model selected. Please select a model from the dropdown."
      );
    }

    const providerInfo = await this.getProviderForModel(model);
    if (!providerInfo) {
      throw new Error(
        `Model not found or API key not configured for model: ${model}. Please configure the API key in settings.`
      );
    }

    // Ollama doesn't need API key validation
    if (providerInfo.provider.id !== "ollama" && !providerInfo.apiKey) {
      throw new Error(
        `No API key configured for model: ${model}. Please configure the API key in settings.`
      );
    }

    // Add language instruction based on user's manual setting if it's not English
    let finalUserMessage = userMessage;
    const responseLanguage =
      multiProviderSettings.responseLanguage || "English";
    if (responseLanguage !== "English") {
      finalUserMessage =
        userMessage + `\n\nIMPORTANT: Please respond in ${responseLanguage}.`;
    }

    // Use LLMUtil with tool calling for all providers (including Ollama simulation)
    const systemMessage = this.getSystemMessage(context);

    try {
      console.log("ğŸ”§ AI Service å‘é€æ¶ˆæ¯:", {
        provider: providerInfo.provider.id,
        model: model,
        hasApiKey: !!providerInfo.apiKey,
        userMessageLength: finalUserMessage.length,
        systemMessageLength: systemMessage.length,
      });

      const result = await LLMUtil.generateResponseWithTools(
        {
          provider: providerInfo.provider.id,
          model: model,
          apiKey: providerInfo.apiKey,
          baseUrl: providerInfo.provider.baseUrl,
          temperature: multiProviderSettings.temperature || 0.7,
          maxTokens: multiProviderSettings.maxTokens || 4000,
        },
        [
          { role: "system", content: systemMessage },
          { role: "user", content: finalUserMessage },
        ]
      );

      console.log("ğŸ”§ AI Service å·¥å…·è°ƒç”¨ç»“æœ:", {
        hasToolResults: !!result.toolResults,
        toolCallCount: result.toolResults?.length || 0,
        responseLength: result.text.length,
        usage: result.usage,
      });

      return result.text;
    } catch (error: any) {
      console.error("âŒ AI Service é”™è¯¯:", {
        provider: providerInfo.provider.id,
        model: model,
        error: error.message,
        stack: error.stack,
      });

      // Provide more specific error messages
      if (error.message.includes("API key")) {
        throw new Error(
          `API å¯†é’¥é”™è¯¯ (${providerInfo.provider.name}): ${error.message}`
        );
      } else if (
        error.message.includes("rate limit") ||
        error.message.includes("quota")
      ) {
        throw new Error(
          `è¯·æ±‚é¢‘ç‡é™åˆ¶æˆ–é…é¢ä¸è¶³ (${providerInfo.provider.name}): ${error.message}`
        );
      } else if (
        error.message.includes("network") ||
        error.message.includes("fetch")
      ) {
        throw new Error(
          `ç½‘ç»œè¿æ¥é”™è¯¯ (${providerInfo.provider.name}): ${error.message}`
        );
      } else {
        throw new Error(
          `AI å“åº”å¤±è´¥ (${providerInfo.provider.name}): ${error.message}`
        );
      }
    }
  }

  static async sendMessage(
    settings: AISettings,
    userMessage: string,
    context: string
  ): Promise<string> {
    // Ollama doesn't need API key validation
    if (settings.provider !== "ollama" && !settings.apiKey) {
      throw new Error(
        "API key not configured. Please set your API key in the extension settings."
      );
    }

    const systemMessage = this.getSystemMessage(context);

    // Handle Ollama requests separately
    if (settings.provider === "ollama") {
      const result = await LLMUtil.handleOllamaRequest(
        {
          provider: settings.provider,
          model: settings.model,
          apiKey: settings.apiKey,
          temperature: settings.temperature || 0.7,
          maxTokens: settings.maxTokens || 4000,
        },
        [
          { role: "system", content: systemMessage },
          { role: "user", content: userMessage },
        ]
      );
      return result.text;
    }

    // Use LLMUtil for other providers
    try {
      const result = await LLMUtil.generateResponse(
        {
          provider: settings.provider,
          model: settings.model,
          apiKey: settings.apiKey,
          baseUrl: AI_PROVIDERS.find((p) => p.id === settings.provider)
            ?.baseUrl,
          temperature: settings.temperature || 0.7,
          maxTokens: settings.maxTokens || 4000,
        },
        [
          { role: "system", content: systemMessage },
          { role: "user", content: userMessage },
        ]
      );

      return result.text;
    } catch (error: any) {
      console.error("AI Service Error:", error);
      throw new Error(`Failed to get AI response: ${error.message}`);
    }
  }

  private static getSystemMessage(context: string): string {
    return `ä½ æ˜¯ Roam Research çš„AIåŠ©æ‰‹ï¼Œæ‹¥æœ‰ getRoamNotes å·¥å…·è·å–ç¬”è®°æ•°æ®ã€‚

**å·¥å…·è°ƒç”¨è§„åˆ™ï¼š**
- æ—¶é—´æŸ¥è¯¢ï¼š"æ˜¨å¤©"â†’{date:"YYYY-MM-DD"}ï¼Œ"ä¸Šå‘¨"â†’{startDate:"YYYY-MM-DD",endDate:"YYYY-MM-DD"}
- é¡µé¢æŸ¥è¯¢ï¼š"è¿™ä¸ªé¡µé¢"â†’{currentPageContext:true}ï¼Œ"æŸé¡µé¢"â†’{pageTitle:"é¡µé¢å"}
- å¼•ç”¨æŸ¥è¯¢ï¼š"å…³äºXçš„ç¬”è®°"â†’{referencedPage:"X"}
- æœç´¢æŸ¥è¯¢ï¼š"åŒ…å«Xçš„å†…å®¹"â†’{searchTerm:"X"}

**å“åº”æµç¨‹ï¼š**
1. ç«‹å³è°ƒç”¨ getRoamNotes å·¥å…·ï¼ˆæ— éœ€è§£é‡Šï¼‰
2. åŸºäºå·¥å…·ç»“æœåˆ†æå’Œæ€»ç»“
3. ç”¨ä¸­æ–‡å›åº”ä¸­æ–‡æŸ¥è¯¢ï¼Œè‹±æ–‡å›åº”è‹±æ–‡æŸ¥è¯¢

**æ ¸å¿ƒåŸåˆ™ï¼š**
- å§‹ç»ˆåŸºäºçœŸå®å·¥å…·æ•°æ®ï¼Œä¸ç¼–é€ å†…å®¹
- å¼•ç”¨æ ¼å¼ï¼š((uid)) å’Œ [[é¡µé¢å]]
- ç©ºç»“æœæ—¶è¯šå®è¯´æ˜æ²¡æœ‰ç›¸å…³ç¬”è®°
- é¼“åŠ±ç”¨æˆ·å†™ä½œå’Œåæ€

${context ? `\n**ä¸Šä¸‹æ–‡ï¼š**${context}` : ""}

ç«‹å³å¼€å§‹å·¥å…·è°ƒç”¨ï¼Œä¸è¦è¿‡åº¦è§£é‡Šæ„å›¾ã€‚`;
  }

  /**
   * Get available Ollama models from the service
   */
  static async getOllamaModels(baseUrl?: string): Promise<string[]> {
    return LLMUtil.getOllamaModels(baseUrl);
  }

  /**
   * Test Ollama connection and list available models
   */
  static async testOllamaConnection(
    baseUrl?: string
  ): Promise<{ isConnected: boolean; models?: string[]; error?: string }> {
    return LLMUtil.testOllamaConnection(baseUrl);
  }

  static validateSettings(settings: AISettings): {
    isValid: boolean;
    error?: string;
  } {
    // Ollama doesn't need API key validation
    if (settings.provider !== "ollama" && !settings.apiKey?.trim()) {
      return { isValid: false, error: "API key is required" };
    }

    if (!settings.provider) {
      return { isValid: false, error: "AI provider is required" };
    }

    if (!settings.model) {
      return { isValid: false, error: "AI model is required" };
    }

    const provider = AI_PROVIDERS.find((p) => p.id === settings.provider);
    if (!provider) {
      return { isValid: false, error: "Invalid AI provider" };
    }

    if (!provider.models.includes(settings.model)) {
      return { isValid: false, error: "Invalid model for selected provider" };
    }

    return { isValid: true };
  }
}
